## Заметки
- Хотел сделать демо на Хероку, но наша библиотека пытается хранить временные файлы во внутреннем хранилище Ларавел, а с постоянными файлами у хероку есть некоторые сложности.  
Можно было бы организовать хранение на фтп, но на это уже не хватило времени.  
В общем и целом окружение на Хероку все равно отличается от ожидаемого в задании Docker.  
Просто мог бы быть бы наглядный рабочий пример.

- Все что происходит внутри RowsImport не покрыто тестами.  
Просто не успел продумать как эту часть правильно тестировать.  
Чтобы грамотно их организовать очень желательно было бы сначала разобраться со всеми описанными ниже проблемами связанными с очередью.

- Когда мы используем чтение по частям наша - библиотека не умеет вычислять формулы, которые ссылаются на другой кусок, прочитанный ранее.  
Ввиду того что в файле примера все ID были формулой сделал временное решение - чтение по 1000000 строк (чтобы прочитать весь файл, хотя правильней было бы INF, но метод chunkSize зачем-то хочет именно int), а в процессе обработки запись инфы только о нужных 1000. 

- Не совсем понятно зачем в задании указано хранить инфу о парсинге в редис.   
Библиотека парсинга вполе себе сносно умеет разбивать чтение на куски по 1000 и создавать им Jobs.  
Но ввиду того что это было отдельно указано в задании - инфа таки сохраняется в редис:  
  
  - при создании задания  
  - после каждого прохода который обрабатывает 1000 строк - проверяем если мы дошли до конца файла то все ок    
если нет то записываем новое значение на 1000 больше предыдущего и добавляем новое задание с данными того же файла  

   Все это дополнительно приводит к тому что если загружено несколько файлов то за один запуск крона 1000 строк обрабатывается во всех.

- не совсем понятно зачем все же крон, ведь логичней добавить queue:work в супервайзер чтобы оно всегда работало
нии написано хранить) и зачем там крон (может зря привязал ограничение на обработку по 1000 к крону, а достаточно было бы чтоб он запускал очередь и она уже работала пока не выполнит все)

- фильтры для парсенных значений не успел
- парсенные значения разбиты по файлам и выглядят не очень интересно с тем файлом что был для примера.  
Если вдруг все же имелось ввиду что они должны быть в одном месте из всех файлов - переделка для этого минимальна. Значения при этом будут сгруппированы по датам

